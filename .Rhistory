# Tabla 2
resultado_final_caenes %>%
kbl(caption =  "\\label{caenes_audi_final}Casos codificados correctamente CAENES (muestra de 1.500 casos)" ,
booktabs = T,
format = "latex",
align=c(rep('c',times = ncol(resultado_final_ciuo)))
) %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = c("HOLD_position"), full_width = F, font_size = 9.5) %>%
footnote(general_title = "", general = footnote, footnote_as_chunk = T )
origen <- caenes %>%
filter(glosa_caenes != "88") %>%
group_by(origen) %>%
summarise(frecuencia = n()) %>%
ungroup() %>%
mutate(total = sum(frecuencia),
porcentaje = round(frecuencia / total * 100, 1),
porcentaje = format(porcentaje ,decimal.mark=",",scientific=FALSE),
frecuencia = format(frecuencia ,big.mark=".",scientific=FALSE)
) %>%
select(-total)
# Tabla 3
origen %>%
kbl(caption = "\\label{origen_cod}Origen de la codificación",
booktabs = T,
align=c(rep('c',times = ncol(origen))),
format = "latex") %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = c("HOLD_position"), full_width = F, font_size = 9.5) %>%
footnote(general_title = "", general = footnote, footnote_as_chunk = T)
total_999 <- caenes %>%
filter(glosa_caenes != "88") %>%
group_by(cod_final) %>%
filter(cod_final == "999") %>%
summarise(contar = n())
por_999 <- total_999$contar / nrow(caenes) * 100
por_999 <- format(round(por_999, 1) , decimal.mark = ",", big.mark=".",scientific=FALSE)
plot <- caenes %>%
filter(glosa_caenes != "88") %>%
group_by(cod_final) %>%
summarise(contar = n()) %>%
ggplot(aes(x = cod_final, y = contar ) ) +
geom_bar(stat = "identity") +
labs(
x = "códigos",
y = "frecuencia",
caption = footnote
) +
theme(axis.text.x = element_text(angle = 60, size = 6),
plot.title = element_text(hjust = 0.5),
plot.caption = element_text(hjust = 0)
)
ggsave("imagenes/distribucion_caenes.pdf", width = 7, height = 4, units = "in")
glosas_999 <- caenes %>%
filter(glosa_caenes != "88") %>%
filter(cod_final == "999" & glosa_caenes != "88") %>%
select(glosa_caenes) %>%
slice(1:8)
glosas_999 %>%
kbl(caption =  "\\label{cod_999_caenes}Códigos 999 (algunos ejemplos)",
booktabs = T,
format = "latex"
) %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = c("HOLD_position"), full_width = F, font_size = 9.5) %>%
footnote(general_title = "", general = footnote, footnote_as_chunk = T)
caenes %>%
filter(glosa_caenes != "88") %>%
count(levantamiento) %>%
mutate(porcentaje = round(n / sum(n) * 100, 1)) %>%
rename(frecuencia = n) %>%
mutate(frecuencia = format(frecuencia ,big.mark=".",scientific=FALSE)) %>%
kbl(caption = "\\label{capi_papi}Procedencia CAPI y PAPI",
booktabs = T,
format = "latex",
align=c(rep('c',times = ncol(origen)))
) %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = c("HOLD_position"), full_width = F, font_size = 9.5) %>%
footnote(general_title = "", general = footnote, footnote_as_chunk = T)
n_88 <- ciuo %>%
filter(b1_1 == "88" & b1_2 == "88") %>%
nrow()
ciuo2 <- ciuo %>%
mutate(missing = case_when(
b1_1 == "88" & b1_2 != "88" ~ "missing oficio",
b1_1 != "88" & b1_2 == "88" ~ "missing tareas",
b1_1 == "88" & b1_2 == "88" ~ "missing oficio y tareas",
T ~ "válido"
) )
ciuo2 %>%
count(missing) %>%
rename(frecuencia = n) %>%
mutate(porcentaje = round(frecuencia / sum(frecuencia) * 100, 1)) %>%
mutate(frecuencia = format(frecuencia, decimal.mark = ",", big.mark=".",scientific=FALSE),
porcentaje = format(porcentaje, decimal.mark = ",", big.mark=".",scientific=FALSE)
) %>%
kbl(caption = "\\label{missing_ciuo}Cantidad valores perdidos CIUO-08.CL",
booktabs = T,
format = "latex"
) %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = c("HOLD_position"), full_width = F, font_size = 9.5) %>%
footnote(general_title = "", general = footnote, footnote_as_chunk = T)
footnote
footnote_ajustado <- "Fuente: elaboración propia,\nInstituto Nacional de Estadísticas "
origen %>%
kbl(caption = "\\label{origen_ciuo}Origen de la codificación CIUO-08.CL",
booktabs = T,
format = "latex"
)  %>%
kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = c("HOLD_position"), full_width = F, font_size = 9.5) %>%
footnote(general_title = "", general = footnote_ajustado, footnote_as_chunk = T)
footnote <- "Fuente: elaboración propia, Instituto Nacional de Estadísticas "
fn1 = 'Fuente: elaboración propia'
fn2 = 'Instituto Nacional de Estadísticas'
origen <- ciuo2 %>%
filter(missing == "válido") %>%
group_by(origen) %>%
summarise(frecuencia = n()) %>%
ungroup() %>%
mutate(total = sum(frecuencia),
porcentaje = round(frecuencia / total * 100, 1),
porcentaje = format(porcentaje ,decimal.mark=",",scientific=FALSE),
frecuencia = format(frecuencia ,big.mark=".",scientific=FALSE)
) %>%
select(-total)
origen %>%
kbl(caption = "Origen de la codificación CIUO-08.CL", booktabs = T)  %>%
kable_styling( font_size = 9.5 ) %>%
footnote(general_title = c(fn1, fn2), general = footnote, footnote_as_chunk = T)
mtcars
df <- tibble(
x = list(1, 2:3, 4:6)
)
df
df$x
df <- tribble(
~ n, ~ min, ~ max,
4,     0,     1,
2,    10,   100,
3,   100,  1000,
)
df2 <- df %>%
rowwise() %>%
mutate(data = list(runif(n, min, max)))
df2
df2$data[[2]]
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "_{.fn}_{.col}"))
names(mtcars2)
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "{str_replace(.fn), pattern = 'n', replacement = '')}_{.col}"))
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "str_replace({.fn}, replacement = 'k', pattern = 'n'  )_{.col}"))
names(mtcars2)
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "{str_replace({.fn}, replacement = 'k', pattern = 'n'  )}_{.col}"))
names(mtcars2)
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "{str_replace(.col, replacement = 'k', pattern = 'n'  )}_{.fn}"))
names(mtcars2)
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "{str_replace({.col}, replacement = 'k', pattern = 'n'  )}_{.fn}"))
names(mtcars2)
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "{str_replace({.col}, replacement = 'k', pattern = 'm'  )}_{.fn}"))
names(mtcars2)
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp") , .fns =  list(norm = ~(. - min(.)) / (max(.) - min(.)) ),
.names = "{str_replace(.col, replacement = 'k', pattern = 'm'  )}_{.fn}"))
names(mtcars2)
do_silly_stuff <- function(x) {
normalizar <-  (x - min(x)) / (max(x) - min(x))
norm_media <-  normalizar + mean(normalizar)
norm_mediana <- norm_media / median(norm_media)
return(norm_mediana)
}
do_silly_stuff <- function(x, encuesta) {
if (encuesta == "ene") {
normalizar <-  (x - min(x)) / (max(x) - min(x))
norm_media <-  normalizar + mean(normalizar)
norm <- norm_media / median(norm_media)
} else {
normalizar <-  (x - min(x)) / (max(x) - min(x))
norm <-  normalizar + mean(normalizar)
}
return(norm)
}
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp"),
.fns = list(norm = ~do_silly_stuff(. , encuesta = "ene"))  ))
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp"),
.fns = list(norm = do_silly_stuff)))
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp"),
.fns = list(norm = do_silly_stuff)))
mtcars2 <- mtcars %>%
mutate(across(c("mpg", "disp"),
.fns = list(norm = ~do_silly_stuff(. , encuesta = "ene"))  ))
wrapper <- function() {
sumar_xy <- function(x, y) {
x + y
}
return(environment(sumar_xy))
}
wrapper()
sumar_xyz <- function(x, y, z = 5) {
x + y + z
}
sumar_xyz(1, 2, 10)
get_stats <- function(x) {
c(mean(x), min(x), max(x), median(x), quantile(x, 0.01), quantile(x, 0.99))
}
set.seed(123)
get_stats(rnorm(n = 10000))
get_stats <- function(x) {
vector <- c(mean(x), min(x), max(x), median(x), quantile(x, 0.01), quantile(x, 0.99))
}
set.seed(123)
get_stats(rnorm(n = 10000))
vectorized_function <- function(x, func) {
new_x <-  do_silly_stuff(x)
out <-  func(new_x)
return(out)
}
vectorized_function(c(rnorm(10)), median)
do_silly_stuff <- function(x, encuesta) {
normalizar <-  (x - min(x)) / (max(x) - min(x))
norm_media <-  normalizar + mean(normalizar)
norm <- norm_media / median(norm_media)
return(norm)
}
vectorized_function <- function(x, func) {
new_x <-  do_silly_stuff(x)
out <-  func(new_x)
return(out)
}
vectorized_function(c(rnorm(10)), median)
81**(1/3)
factory_root <- function(power_input) {
new_power <- function(x) {
x**(1/power_input)
}
return(new_power)
}
root2 <- factory_root(2)
root3 <- factory_root(3)
root4 <- factory_root(4)
root2(4)
root4(64)
root4(16)
glosa <- "manipulador de alimentos prepara colaciones"
request <-  httr::POST("http://143.198.79.143:8080/predict",
encode = "json",
body =  list(text = glosa,
classification = "ciuo",
digits = 2)
)
# Revisar el status
httr::status_code(request)
# Extraer el contenido
response <- httr::content(request)
# Imprimir resultado
response
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message = FALSE)
#Cargar datos con la siguiente información: tamaño de glosas, tamaño de palabras, diversidad léxica
load(file = "datos/total_stats2.RData")
#Cargar la misma información, pero para los meses en los que se levantó la piloto
load(file = "datos/total_stats_piloto.RData")
#Unir ambas bases de datos para graficar de manera más fluida
total_stats2 <- mutate(total_stats2, origen = "oficial")
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(xaringanthemer)
#style_duo_accent(
# primary_color = "#1381B0",
#secondary_color = "#FF961C",
#inverse_header_color = "#FFFFFF"
#)
library(readxl); library(tidyverse)
piloto <- read_excel("datos/piloto audit v2 ene_dm_cca_v1 (19-06-2020).xlsx")
abril <- read_excel("datos/20200701_basecaenes_final.xlsx")
audi_2019 <- read_excel("datos/191210 BBDD CAENES_mjj.xlsx")
#Datos prueba piloto
piloto <- piloto %>%
mutate(`CONFORMIDAD  CAENES NOMEN` = tolower(`CONFORMIDAD  CAENES NOMEN`))
piloto_table <- prop.table(table(piloto$`CONFORMIDAD  CAENES NOMEN`))*100
piloto_table <- as.data.frame(piloto_table) %>%
mutate(origen = "piloto ASO 2019",
Var1 = as.character(Var1),
Var1 = if_else(Var1 == "sc", "sin clasificar", Var1))
#Datos abril 2020
abril <- abril %>%
mutate(`Estado de Conformidad CAENES analista` = if_else(`Código CAENES analista` == "S/C",
"sin clasificar", `Estado de Conformidad CAENES analista`),
`Estado de Conformidad CAENES analista` = tolower(`Estado de Conformidad CAENES analista`))
abril_table <-  prop.table(table(abril$`Estado de Conformidad CAENES analista`)) * 100
abril_table <- as.data.frame(abril_table) %>%
mutate(origen = "abril 2020",
Var1 = as.character(Var1))
#Datos auditoría abril 2019
audi_2019_table <-  prop.table(table(audi_2019$`CONFORMIDAD  CAENES NOMEN`))*100
audi_2019_table <- as.data.frame(audi_2019_table) %>%
mutate(origen = "MJJ 2019",
Var1 = as.character(Var1),
Var1 = tolower(Var1),
Var1 = if_else(Var1 == "sc", "sin clasificar", Var1))
#Generar gráfico
tabla_graf <- rbind(piloto_table, abril_table, audi_2019_table) %>%
mutate(Var1 = if_else(Var1 == "conforme con observaciones", "conforme\ncon observaciones", Var1),
origen = as.factor(origen))
tabla_graf$origen <- fct_relevel(tabla_graf$origen, "MJJ 2019", "piloto ASO 2019", "abril 2020")
ggplot(tabla_graf, aes(x = Var1, y = Freq, fill = origen)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Resultado de últimas auditorías",
y = "porcentaje") +
geom_text(aes(label=round(Freq, 2)), position=position_dodge(width=0.9), vjust=-0.25)+
theme(text = element_text(size = 15),
plot.title = element_text(hjust = 0.5),
axis.title.x=element_blank(),
legend.title = element_blank())
#Cargar datos con la siguiente información: tamaño de glosas, tamaño de palabras, diversidad léxica
load(file = "datos/total_stats2.RData")
#Cargar la misma información, pero para los meses en los que se levantó la piloto
load(file = "datos/total_stats_piloto.RData")
#Unir ambas bases de datos para graficar de manera más fluida
total_stats2 <- mutate(total_stats2, origen = "oficial")
total_stats_piloto <- mutate(total_stats_piloto, origen = "piloto")
oficial_piloto <- bind_rows(total_stats2, total_stats_piloto)
#Generar gráfico con el tamaño promedio de glosas
oficial_piloto %>%
ggplot(aes(x = date2, y = mean, color = origen )) +
geom_line(aes(group = origen), size = 1.5) +
geom_vline(xintercept = "2020-01", linetype="dashed", color = "red") +
labs(title="Número de palabras por glosa en CAENES") +
xlab("Fecha") +
ylab("Promedio de palabras") +
theme(text = element_text(size = 15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5),
axis.title.x  = element_blank(),
legend.title = element_blank())
oficial_piloto
#Generar gráfico con el tamaño promedio de glosas
oficial_piloto %>%
ggplot(aes(x = date2, y = mean, color = origen )) +
geom_line(aes(group = origen), size = 1.5) +
geom_vline(xintercept = "2020-01", linetype="dashed", color = "red") +
labs(title="Número de palabras por glosa en CAENES") +
xlab("Fecha") +
ylab("Promedio de palabras") +
theme(text = element_text(size = 15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5),
axis.title.x  = element_blank(),
legend.title = element_blank())
oficial_piloto
#Generar gráfico con el tamaño promedio de glosas
oficial_piloto %>%
ggplot(aes(x = date2, y = mean, color = origen )) +
geom_line(aes(group = origen), size = 1.5) +
geom_vline(xintercept = "2020-01", linetype="dashed", color = "red") +
labs(title="Número de palabras por glosa en CAENES") +
xlab("Fecha") +
ylab("Promedio de palabras") +
theme(text = element_text(size = 15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5),
axis.title.x  = element_blank(),
legend.title = element_blank())
oficial_piloto
#Generar gráfico con el tamaño promedio de glosas
oficial_piloto %>%
ggplot(aes(x = date2, y = mean, color = origen )) +
geom_line(aes(group = origen), size = 1.5) +
geom_vline(xintercept = "2020-01", linetype="dashed", color = "red") +
labs(title="Número de palabras por glosa en CAENES") +
xlab("Fecha") +
ylab("Promedio de palabras") +
theme(text = element_text(size = 15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5),
axis.title.x  = element_blank(),
legend.title = element_blank())
View(oficial_piloto)
oficial_piloto
View(oficial_piloto)
View(oficial_piloto)
#Generar gráfico con el número de palabras diferentes
ggplot(data = oficial_piloto, aes(x = as.factor(date2), y = mean_word, color = origen)) +
geom_line(aes(group = origen), size = 1.5) +
geom_vline(xintercept = "2020-01", linetype="dashed", color = "red") +
labs(title="Largo promedio de las palabras en CAENES",
subtitle = "Número promedio de caracteres") +
xlab("Fecha") +
ylab("Media de caracteres") +
theme(text = element_text(size = 15),
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5),
axis.title.x  = element_blank(),
legend.title = element_blank())
knitr::opts_chunk$set(echo = F, warning = F, message = F, fig.align="center")
resutados_caenes <- read_feather("src/data/resultados/results_caenes.feather")
library(feather)
resutados_caenes <- read_feather("src/data/resultados/results_caenes.feather")
resutados_ciuo <- read_feather("src/data/resultados/results_ciuo.feather")
resutados_caenes %>%
mutate_at(vars(-modelo), ~round(., 4)) %>%
filter(str_detect(string = modelo, pattern = "1"))
resutados_caenes
resutados_caenes <- read_feather("src/data/resultados/results_caenes.feather")
resutados_caenes <- resutados_caenes %>%
mutate(modelo = case_when(
modelo == "emb_simple_1d" ~ "embeddings feed-forward 1d",
modelo == "emb_simple_2d" ~ "embeddings feed-forward 2d",
modelo == "emb_gru_1d" ~ "embeddings GRU 1d",
modelo == "emb_gru_2d" ~ "embeddings GRU 2d",
modelo == "seq_1d" ~ "secuencias 1d",
modelo == "seq_2d" ~ "secuencias 2d",
T ~ modelo
))
resutados_caenes
resutados_caenes <- read_feather("src/data/resultados/results_caenes.feather")
resutados_caenes <- resutados_caenes %>%
mutate(modelo = case_when(
modelo == "emb_simple_1d" ~ "embeddings feed-forward 1d",
modelo == "emb_simple_2d" ~ "embeddings feed-forward 2d",
modelo == "emb_gru_1d" ~ "embeddings GRU 1d",
modelo == "emb_gru_2d" ~ "embeddings GRU 2d",
modelo == "seq_1d" ~ "secuencias 1d",
modelo == "seq_2d" ~ "secuencias 2d",
modelo == "tfidf_1d" ~ "TF-IDF 1d",
modelo == "tfidf_2d" ~ "TF-IDF 2d",
T ~ modelo
))
resutados_caenes
resutados_ciuo <- resutados_ciuo %>%
mutate(modelo = case_when(
modelo == "emb_simple_1d" ~ "embeddings feed-forward 1d",
modelo == "emb_simple_2d" ~ "embeddings feed-forward 2d",
modelo == "emb_gru_1d" ~ "embeddings GRU 1d",
modelo == "emb_gru_2d" ~ "embeddings GRU 2d",
modelo == "seq_1d" ~ "secuencias feed-forward 1d",
modelo == "seq_2d" ~ "secuencias feed-forward 2d",
modelo == "tfidf_1d" ~ "TF-IDF 1d",
modelo == "tfidf_2d" ~ "TF-IDF 2d",
T ~ modelo
))
library(httr)
library(feather)
caenes <- read_feather("src/data/split_train_test/test.feather")
request <-  httr::POST("http://10.91.160.65:9292/predict",
encode = "json",
body =  list(text = caenes$glosa_caenes[1:10],
classification = "caenes",
digits = 1)
)
request <-  httr::POST("http://10.91.160.65:9292/predict",
encode = "json",
body =  list(text = caenes$glosa_caenes[1:10],
classification = "caenes",
digits = 1)
)
request <- httr::POST("http://10.91.160.65:9292/predict?text=venta%20de%20neumático&digits=1&classification=caenes")
request <- httr::POST("http://10.91.160.65:9090/predict?text=venta%20de%20neumático&digits=1&classification=caenes")
request <- httr::POST("http://10.91.160.65:9292/predict?text=miner%C3%ADa%20de%20cobre&digits=1&classification=caenes")
# Revisar el status
httr::status_code(request)
caenes <- read_feather("src/data/split_train_test/test.feather")
request <-  httr::POST("http://10.91.160.65:9292/predict",
encode = "json",
body =  list(text = caenes$glosa_caenes[1:10],
classification = "caenes",
digits = 1)
)
# Revisar el status
httr::status_code(request)
# Extraer el contenido
response <- httr::content(request)
# Impimir las dos primeras predicciones
tabla <- map(response[1:5], as.data.frame) %>%
bind_rows()
tabla
request <-  httr::POST("http://143.198.79.143:8787/"
encode = "json",
request <-  httr::POST("http://143.198.79.143:8787/",
encode = "json",
body =  list(text = caenes$glosa_caenes[1:10],
classification = "caenes",
digits = 1)
)
# Revisar el status
httr::status_code(request)
request <- httr::GET("http://143.198.79.143:8080/download?dataset=caenes")
# Revisar el status
httr::status_code(request)
# Extraer el contenido
dataset_caenes <- httr::content(request)
# Ejemplo primera fila del dataset
dataset_caenes[[1]]
